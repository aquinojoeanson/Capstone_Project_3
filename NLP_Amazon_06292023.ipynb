{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d3ed6d",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e319372",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "DataSet\n",
    "Data Wrangling\n",
    "NLP Pre-Processing\n",
    "HTML Entities\n",
    "Extracting the root word\n",
    "Removing Accents\n",
    "Removing Punctuations\n",
    "Converting to Lower Case\n",
    "Removing Stop Words\n",
    "Removing Extra Spaces\n",
    "Tokenization\n",
    "Phrase Modeling\n",
    "Unigrams\n",
    "Bigrams\n",
    "Trigrams\n",
    "Creating the Vocabulary\n",
    "Count-based Feature Engineering\n",
    "Bag of Words Model\n",
    "TF-IDF Model\n",
    "Word Embedding for Feature Engineering\n",
    "Final Dataframe\n",
    "Principal Component Analysis\n",
    "Exploratory Data Analysis\n",
    "More on Word2Vec\n",
    "t-SNE\n",
    "Word Algebra\n",
    "Books + Touchscreen\n",
    "Cheap – Quality\n",
    "Tablet – Phone\n",
    "Named-Entity Recognition\n",
    "Dependency Tree\n",
    "Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec4b8d",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691a124",
   "metadata": {},
   "source": [
    "The Amazon dataset contains the customer reviews from http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be382e4",
   "metadata": {},
   "source": [
    "* asin - Unique ID of the product being reviewed, string\n",
    "* helpful - A list with two elements: the number of users that voted helpful, and the total number of users that voted on the review (including the not helpful votes), list\n",
    "* overall - The reviewer's rating of the product, int64\n",
    "* reviewText - The review text itself, string\n",
    "* reviewerID - Unique ID of the reviewer, string\n",
    "* reviewerName - Specified name of the reviewer, string\n",
    "* summary - Headline summary of the review, string\n",
    "* unixReviewTime - Unix Time of when the review was posted, string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17683773",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e180b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503aa534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aquinojoeanson/Desktop/SPRINGBOARD/Capstone_Project_3/Notebook\n"
     ]
    }
   ],
   "source": [
    "MyWorkingDir = os.getcwd()\n",
    "print(MyWorkingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7184d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2JXAZZI9PHK9Z</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>Billy G. Noland \"Bill Noland\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>5</td>\n",
       "      <td>HDMI Nook adapter cable</td>\n",
       "      <td>1388707200</td>\n",
       "      <td>01 3, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A2P5U7BDKKT7FW</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>Christian</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>The cable is very wobbly and sometimes disconn...</td>\n",
       "      <td>2</td>\n",
       "      <td>Cheap proprietary scam</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>04 27, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAZ084UMH8VZ2</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>D. L. Brown \"A Knower Of Good Things\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This adaptor is real easy to setup and use rig...</td>\n",
       "      <td>5</td>\n",
       "      <td>A Perfdect Nook HD+ hook up</td>\n",
       "      <td>1399161600</td>\n",
       "      <td>05 4, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AEZ3CR6BKIROJ</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>Mark Dietter</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This adapter easily connects my Nook HD 7&amp;#34;...</td>\n",
       "      <td>4</td>\n",
       "      <td>A nice easy to use accessory.</td>\n",
       "      <td>1405036800</td>\n",
       "      <td>07 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>Matenai</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>This product really works great but I found th...</td>\n",
       "      <td>5</td>\n",
       "      <td>This works great but read the details...</td>\n",
       "      <td>1390176000</td>\n",
       "      <td>01 20, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                           reviewerName  \\\n",
       "0   AO94DHGC771SJ  0528881469                                amazdnu   \n",
       "1   AMO214LNFCEI4  0528881469                        Amazon Customer   \n",
       "2  A3N7T0DY83Y4IG  0528881469                          C. A. Freeman   \n",
       "3  A1H8PY3QHMQQA0  0528881469               Dave M. Shaw \"mack dave\"   \n",
       "4  A24EV6RXELQZ63  0528881469                            Wayne Smith   \n",
       "5  A2JXAZZI9PHK9Z  0594451647          Billy G. Noland \"Bill Noland\"   \n",
       "6  A2P5U7BDKKT7FW  0594451647                              Christian   \n",
       "7   AAZ084UMH8VZ2  0594451647  D. L. Brown \"A Knower Of Good Things\"   \n",
       "8   AEZ3CR6BKIROJ  0594451647                           Mark Dietter   \n",
       "9  A3BY5KCNQZXV5U  0594451647                                Matenai   \n",
       "\n",
       "    helpful                                         reviewText  overall  \\\n",
       "0    [0, 0]  We got this GPS for my husband who is an (OTR)...        5   \n",
       "1  [12, 15]  I'm a professional OTR truck driver, and I bou...        1   \n",
       "2  [43, 45]  Well, what can I say.  I've had this unit in m...        3   \n",
       "3   [9, 10]  Not going to write a long review, even thought...        2   \n",
       "4    [0, 0]  I've had mine for a year and here's what we go...        1   \n",
       "5    [3, 3]  I am using this with a Nook HD+. It works as d...        5   \n",
       "6    [0, 0]  The cable is very wobbly and sometimes disconn...        2   \n",
       "7    [0, 0]  This adaptor is real easy to setup and use rig...        5   \n",
       "8    [0, 0]  This adapter easily connects my Nook HD 7&#34;...        4   \n",
       "9    [3, 3]  This product really works great but I found th...        5   \n",
       "\n",
       "                                    summary  unixReviewTime   reviewTime  \n",
       "0                           Gotta have GPS!      1370131200   06 2, 2013  \n",
       "1                         Very Disappointed      1290643200  11 25, 2010  \n",
       "2                            1st impression      1283990400   09 9, 2010  \n",
       "3                   Great grafics, POOR GPS      1290556800  11 24, 2010  \n",
       "4    Major issues, only excuses for support      1317254400  09 29, 2011  \n",
       "5                   HDMI Nook adapter cable      1388707200   01 3, 2014  \n",
       "6                    Cheap proprietary scam      1398556800  04 27, 2014  \n",
       "7               A Perfdect Nook HD+ hook up      1399161600   05 4, 2014  \n",
       "8             A nice easy to use accessory.      1405036800  07 11, 2014  \n",
       "9  This works great but read the details...      1390176000  01 20, 2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_json('/Users/aquinojoeanson/Desktop/SPRINGBOARD/Capstone_Project_3/Notebook/reviews_Electronics.json', lines = True)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d595fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import pandas as pd\n",
    "\n",
    "#dataset = \"Electronics_5.json\"\n",
    "\n",
    "#if os.path.isfile(dataset):\n",
    "#    df = pd.read_json(\"Electronics_5.json\", lines=True)\n",
    "#else:\n",
    "#    url = r\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\"\n",
    "#    df = pd.read_json(url, compression='gzip', lines=True)\n",
    "\n",
    "#display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43b717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1689188 entries, 0 to 1689187\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   reviewerID      1689188 non-null  object\n",
      " 1   asin            1689188 non-null  object\n",
      " 2   reviewerName    1664458 non-null  object\n",
      " 3   helpful         1689188 non-null  object\n",
      " 4   reviewText      1689188 non-null  object\n",
      " 5   overall         1689188 non-null  int64 \n",
      " 6   summary         1689188 non-null  object\n",
      " 7   unixReviewTime  1689188 non-null  int64 \n",
      " 8   reviewTime      1689188 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 116.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a387372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "condition = lambda row: datetime.fromtimestamp(row).strftime(\"%m-%d-%Y\")\n",
    "df[\"unixReviewTime\"] = df[\"unixReviewTime\"].apply(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc956fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>06-01-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>11-24-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>09-08-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>11-23-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>09-28-2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin              reviewerName   helpful  \\\n",
       "0   AO94DHGC771SJ  0528881469                   amazdnu    [0, 0]   \n",
       "1   AMO214LNFCEI4  0528881469           Amazon Customer  [12, 15]   \n",
       "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman  [43, 45]   \n",
       "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   [9, 10]   \n",
       "4  A24EV6RXELQZ63  0528881469               Wayne Smith    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...        5   \n",
       "1  I'm a professional OTR truck driver, and I bou...        1   \n",
       "2  Well, what can I say.  I've had this unit in m...        3   \n",
       "3  Not going to write a long review, even thought...        2   \n",
       "4  I've had mine for a year and here's what we go...        1   \n",
       "\n",
       "                                  summary unixReviewTime  \n",
       "0                         Gotta have GPS!     06-01-2013  \n",
       "1                       Very Disappointed     11-24-2010  \n",
       "2                          1st impression     09-08-2010  \n",
       "3                 Great grafics, POOR GPS     11-23-2010  \n",
       "4  Major issues, only excuses for support     09-28-2011  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop(labels=\"reviewTime\", axis=1, inplace=True)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c12b2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that's just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!\n"
     ]
    }
   ],
   "source": [
    "print(df[\"reviewText\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776b0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(df.overall.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421a0fa",
   "metadata": {},
   "source": [
    "# NLP Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad516fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I&#8217;m a big fan of the Brainwavz S1 (actually all of their headphones &#8211; have yet to be disappointed with any of their products). The S1 has been my main set for active use (e.g., workouts, runs, etc.) since the flat cable is very durable and resistant to tangles. The S5 keeps all the good features of the S1 and adds to it &#8211; the sound quality is richer and better defined.That&#8217;s not to say the S1 sounds poor &#8211; they are quite good, in fact. But the S5 are better. The highs are better defined and the midrange has more punch to it. The bass comes through clearly without moving into the harsh territory when the volume is pushed (as the S1s can do). The overall sound quality is very pleasing.The build quality seems solid &#8211; as solid as the S1 or better. I love the flat cable! I know that&#8217;s something that is not appreciated by everyone, but for me it&#8217;s been working out wonderfully. Although this (as most other Brainwavz headsets) comes with an excellent hard shell case, I usually tote my earbuds wrapped around my mp3 player in my pocket. Easy to carry; very stressful on the cables and can lead to tangles with round wires. Flat wires, especially those with a thick jacket such as these, survive that abuse with zero problems.The earbuds themselves are more sleekly shaped than the &#8220;can&#8221; style of the S1.Comfort is in line with the customary Brainwavz style, which is to say it&#8217;s outstanding. It comes with a wide range of tips to fit pretty much any ear, plus the Comply foam tips (which are my favorite). If fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response.These are an over-the-ear design much like the S1. I never used that design prior to the S1 and it did take me a little time to get accustomed to it. It became second nature quickly, and the design is a lot more stable when exercising than the conventional in-ear design.These are more expensive than the S1, but you can hear the difference in price. Still, if you&#8217;re looking to keep the cost down a bit, the S1 is an excellent performer as well.Great sound, great comfort, wonderful cable design, and it comes with a solidly made case and lots of eartips. Highly recommend.[Sample provided for review]\n"
     ]
    }
   ],
   "source": [
    "sample_review = df[\"reviewText\"].iloc[1689185]\n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaecb5f",
   "metadata": {},
   "source": [
    "# HTML Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59af0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m a big fan of the Brainwavz S1 (actually all of their headphones – have yet to be disappointed with any of their products). The S1 has been my main set for active use (e.g., workouts, runs, etc.) since the flat cable is very durable and resistant to tangles. The S5 keeps all the good features of the S1 and adds to it – the sound quality is richer and better defined.That’s not to say the S1 sounds poor – they are quite good, in fact. But the S5 are better. The highs are better defined and the midrange has more punch to it. The bass comes through clearly without moving into the harsh territory when the volume is pushed (as the S1s can do). The overall sound quality is very pleasing.The build quality seems solid – as solid as the S1 or better. I love the flat cable! I know that’s something that is not appreciated by everyone, but for me it’s been working out wonderfully. Although this (as most other Brainwavz headsets) comes with an excellent hard shell case, I usually tote my earbuds wrapped around my mp3 player in my pocket. Easy to carry; very stressful on the cables and can lead to tangles with round wires. Flat wires, especially those with a thick jacket such as these, survive that abuse with zero problems.The earbuds themselves are more sleekly shaped than the “can” style of the S1.Comfort is in line with the customary Brainwavz style, which is to say it’s outstanding. It comes with a wide range of tips to fit pretty much any ear, plus the Comply foam tips (which are my favorite). If fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response.These are an over-the-ear design much like the S1. I never used that design prior to the S1 and it did take me a little time to get accustomed to it. It became second nature quickly, and the design is a lot more stable when exercising than the conventional in-ear design.These are more expensive than the S1, but you can hear the difference in price. Still, if you’re looking to keep the cost down a bit, the S1 is an excellent performer as well.Great sound, great comfort, wonderful cable design, and it comes with a solidly made case and lots of eartips. Highly recommend.[Sample provided for review]\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "decoded_review = html.unescape(sample_review)\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "418eaa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im a big fan of the Brainwavz S1 (actually all of their headphones  have yet to be disappointed with any of their products). The S1 has been my main set for active use (e.g., workouts, runs, etc.) since the flat cable is very durable and resistant to tangles. The S5 keeps all the good features of the S1 and adds to it  the sound quality is richer and better defined.Thats not to say the S1 sounds poor  they are quite good, in fact. But the S5 are better. The highs are better defined and the midrange has more punch to it. The bass comes through clearly without moving into the harsh territory when the volume is pushed (as the S1s can do). The overall sound quality is very pleasing.The build quality seems solid  as solid as the S1 or better. I love the flat cable! I know thats something that is not appreciated by everyone, but for me its been working out wonderfully. Although this (as most other Brainwavz headsets) comes with an excellent hard shell case, I usually tote my earbuds wrapped around my mp3 player in my pocket. Easy to carry; very stressful on the cables and can lead to tangles with round wires. Flat wires, especially those with a thick jacket such as these, survive that abuse with zero problems.The earbuds themselves are more sleekly shaped than the can style of the S1.Comfort is in line with the customary Brainwavz style, which is to say its outstanding. It comes with a wide range of tips to fit pretty much any ear, plus the Comply foam tips (which are my favorite). If fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response.These are an over-the-ear design much like the S1. I never used that design prior to the S1 and it did take me a little time to get accustomed to it. It became second nature quickly, and the design is a lot more stable when exercising than the conventional in-ear design.These are more expensive than the S1, but you can hear the difference in price. Still, if youre looking to keep the cost down a bit, the S1 is an excellent performer as well.Great sound, great comfort, wonderful cable design, and it comes with a solidly made case and lots of eartips. Highly recommend.[Sample provided for review]\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\&\\#[0-9]+\\;\"\n",
    "\n",
    "df[\"preprocessed\"] = df[\"reviewText\"].str.replace(pat=pattern, repl=\"\", regex=True)\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302bb68",
   "metadata": {},
   "source": [
    "# Extracting the root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05980387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aquinojoeanson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aquinojoeanson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aquinojoeanson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/aquinojoeanson/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/Users/aquinojoeanson/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/share/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - '/Users/aquinojoeanson/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/share/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:53\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:53\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:48\u001b[0m, in \u001b[0;36mlemmatize_doc\u001b[0;34m(document)\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:31\u001b[0m, in \u001b[0;36mlemmatize_word\u001b[0;34m(tagged_token)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__reader_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# match that of the corpus.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[0;34m(self, root, omw_reader)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovenances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momw_prov\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;66;03m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang_data \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m provdict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1284\u001b[0m provdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1285\u001b[0m fileids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_omw_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m   1287\u001b[0m     prov, langfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(fileid)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/Users/aquinojoeanson/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/share/nltk_data'\n    - '/Users/aquinojoeanson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#import nltk resources\n",
    "resources = [\"wordnet\", \"stopwords\", \"punkt\", \\\n",
    "             \"averaged_perceptron_tagger\", \"maxent_treebank_pos_tagger\"]\n",
    "\n",
    "for resource in resources:\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/\" + resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource)\n",
    "\n",
    "#create Lemmatizer object\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_word(tagged_token):\n",
    "    \"\"\" Returns lemmatized word given its tag\"\"\"\n",
    "    root = []\n",
    "    for token in tagged_token:\n",
    "        tag = token[1][0]\n",
    "        word = token[0]\n",
    "        if tag.startswith('J'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADJ))\n",
    "        elif tag.startswith('V'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.VERB))\n",
    "        elif tag.startswith('N'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.NOUN))\n",
    "        elif tag.startswith('R'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADV))\n",
    "        else:          \n",
    "            root.append(word)\n",
    "    return root\n",
    "\n",
    "def lemmatize_doc(document):\n",
    "    \"\"\" Tags words then returns sentence with lemmatized words\"\"\"\n",
    "    lemmatized_list = []\n",
    "    tokenized_sent = sent_tokenize(document)\n",
    "    for sentence in tokenized_sent:\n",
    "        no_punctuation = re.sub(r\"[`'\\\",.!?()]\", \" \", sentence)\n",
    "        tokenized_word = word_tokenize(no_punctuation)\n",
    "        tagged_token = pos_tag(tokenized_word)\n",
    "        lemmatized = lemmatize_word(tagged_token)\n",
    "        lemmatized_list.extend(lemmatized)\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "#apply our functions\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(lambda row: lemmatize_doc(row))\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef9b70",
   "metadata": {},
   "source": [
    "# Removing Accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b019d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im a big fan of the Brainwavz S1 (actually all of their headphones  have yet to be disappointed with any of their products). The S1 has been my main set for active use (e.g., workouts, runs, etc.) since the flat cable is very durable and resistant to tangles. The S5 keeps all the good features of the S1 and adds to it  the sound quality is richer and better defined.Thats not to say the S1 sounds poor  they are quite good, in fact. But the S5 are better. The highs are better defined and the midrange has more punch to it. The bass comes through clearly without moving into the harsh territory when the volume is pushed (as the S1s can do). The overall sound quality is very pleasing.The build quality seems solid  as solid as the S1 or better. I love the flat cable! I know thats something that is not appreciated by everyone, but for me its been working out wonderfully. Although this (as most other Brainwavz headsets) comes with an excellent hard shell case, I usually tote my earbuds wrapped around my mp3 player in my pocket. Easy to carry; very stressful on the cables and can lead to tangles with round wires. Flat wires, especially those with a thick jacket such as these, survive that abuse with zero problems.The earbuds themselves are more sleekly shaped than the can style of the S1.Comfort is in line with the customary Brainwavz style, which is to say its outstanding. It comes with a wide range of tips to fit pretty much any ear, plus the Comply foam tips (which are my favorite). If fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response.These are an over-the-ear design much like the S1. I never used that design prior to the S1 and it did take me a little time to get accustomed to it. It became second nature quickly, and the design is a lot more stable when exercising than the conventional in-ear design.These are more expensive than the S1, but you can hear the difference in price. Still, if youre looking to keep the cost down a bit, the S1 is an excellent performer as well.Great sound, great comfort, wonderful cable design, and it comes with a solidly made case and lots of eartips. Highly recommend.[Sample provided for review]\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "remove_accent = lambda text: normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(remove_accent)\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8423e89",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627c6c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im a big fan of the Brainwavz S1  actually all of their headphones  have yet to be disappointed with any of their products   The S1 has been my main set for active use  e g   workouts  runs  etc   since the flat cable is very durable and resistant to tangles  The S5 keeps all the good features of the S1 and adds to it  the sound quality is richer and better defined Thats not to say the S1 sounds poor  they are quite good  in fact  But the S5 are better  The highs are better defined and the midrange has more punch to it  The bass comes through clearly without moving into the harsh territory when the volume is pushed  as the S1s can do   The overall sound quality is very pleasing The build quality seems solid  as solid as the S1 or better  I love the flat cable  I know thats something that is not appreciated by everyone  but for me its been working out wonderfully  Although this  as most other Brainwavz headsets  comes with an excellent hard shell case  I usually tote my earbuds wrapped around my mp3 player in my pocket  Easy to carry  very stressful on the cables and can lead to tangles with round wires  Flat wires  especially those with a thick jacket such as these  survive that abuse with zero problems The earbuds themselves are more sleekly shaped than the can style of the S1 Comfort is in line with the customary Brainwavz style  which is to say its outstanding  It comes with a wide range of tips to fit pretty much any ear  plus the Comply foam tips  which are my favorite   If fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response These are an over the ear design much like the S1  I never used that design prior to the S1 and it did take me a little time to get accustomed to it  It became second nature quickly  and the design is a lot more stable when exercising than the conventional in ear design These are more expensive than the S1  but you can hear the difference in price  Still  if youre looking to keep the cost down a bit  the S1 is an excellent performer as well Great sound  great comfort  wonderful cable design  and it comes with a solidly made case and lots of eartips  Highly recommend  Sample provided for review \n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.replace(pat=pattern, repl=\" \", regex=True)\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d50bc",
   "metadata": {},
   "source": [
    "# Converting to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e87f2405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im a big fan of the brainwavz s1  actually all of their headphones  have yet to be disappointed with any of their products   the s1 has been my main set for active use  e g   workouts  runs  etc   since the flat cable is very durable and resistant to tangles  the s5 keeps all the good features of the s1 and adds to it  the sound quality is richer and better defined thats not to say the s1 sounds poor  they are quite good  in fact  but the s5 are better  the highs are better defined and the midrange has more punch to it  the bass comes through clearly without moving into the harsh territory when the volume is pushed  as the s1s can do   the overall sound quality is very pleasing the build quality seems solid  as solid as the s1 or better  i love the flat cable  i know thats something that is not appreciated by everyone  but for me its been working out wonderfully  although this  as most other brainwavz headsets  comes with an excellent hard shell case  i usually tote my earbuds wrapped around my mp3 player in my pocket  easy to carry  very stressful on the cables and can lead to tangles with round wires  flat wires  especially those with a thick jacket such as these  survive that abuse with zero problems the earbuds themselves are more sleekly shaped than the can style of the s1 comfort is in line with the customary brainwavz style  which is to say its outstanding  it comes with a wide range of tips to fit pretty much any ear  plus the comply foam tips  which are my favorite   if fitted properly you end up with zero ear irritation plus excellent sound isolation and bass response these are an over the ear design much like the s1  i never used that design prior to the s1 and it did take me a little time to get accustomed to it  it became second nature quickly  and the design is a lot more stable when exercising than the conventional in ear design these are more expensive than the s1  but you can hear the difference in price  still  if youre looking to keep the cost down a bit  the s1 is an excellent performer as well great sound  great comfort  wonderful cable design  and it comes with a solidly made case and lots of eartips  highly recommend  sample provided for review \n"
     ]
    }
   ],
   "source": [
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.lower()\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc9143",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cfabeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample stop words: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', 'youll', 'youd', 'your', 'yours'] \n",
      "\n",
      "im big fan brainwavz s1  actually headphones  yet disappointed products   s1 main set active use  e g   workouts  runs  etc   since flat cable durable resistant tangles  s5 keeps good features s1 adds  sound quality richer better defined thats say s1 sounds poor  quite good  fact  s5 better  highs better defined midrange punch  bass comes clearly without moving harsh territory volume pushed  s1s   overall sound quality pleasing build quality seems solid  solid s1 better  love flat cable  know thats something appreciated everyone  working wonderfully  although  brainwavz headsets  comes excellent hard shell case  usually tote earbuds wrapped around mp3 player pocket  easy carry  stressful cables lead tangles round wires  flat wires  especially thick jacket  survive abuse zero problems earbuds sleekly shaped style s1 comfort line customary brainwavz style  say outstanding  comes wide range tips fit pretty much ear  plus comply foam tips  favorite   fitted properly end zero ear irritation plus excellent sound isolation bass response ear design much like s1  never used design prior s1 take little time get accustomed  became second nature quickly  design lot stable exercising conventional ear design expensive s1  hear difference price  still  looking keep cost bit  s1 excellent performer well great sound  great comfort  wonderful cable design  comes solidly made case lots eartips  highly recommend  sample provided review \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "stop_words = [word.replace(\"\\'\", \"\") for word in stop_words]\n",
    "\n",
    "print(f\"sample stop words: {stop_words[:15]} \\n\")\n",
    "\n",
    "remove_stop_words = lambda row: \" \".join([token for token in row.split(\" \") \\\n",
    "                                          if token not in stop_words])\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(remove_stop_words)\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18716d8",
   "metadata": {},
   "source": [
    "# Removing Extra Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97954063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im big fan brainwavz s1 actually headphones yet disappointed products s1 main set active use e g workouts runs etc since flat cable durable resistant tangles s5 keeps good features s1 adds sound quality richer better defined thats say s1 sounds poor quite good fact s5 better highs better defined midrange punch bass comes clearly without moving harsh territory volume pushed s1s overall sound quality pleasing build quality seems solid solid s1 better love flat cable know thats something appreciated everyone working wonderfully although brainwavz headsets comes excellent hard shell case usually tote earbuds wrapped around mp3 player pocket easy carry stressful cables lead tangles round wires flat wires especially thick jacket survive abuse zero problems earbuds sleekly shaped style s1 comfort line customary brainwavz style say outstanding comes wide range tips fit pretty much ear plus comply foam tips favorite fitted properly end zero ear irritation plus excellent sound isolation bass response ear design much like s1 never used design prior s1 take little time get accustomed became second nature quickly design lot stable exercising conventional ear design expensive s1 hear difference price still looking keep cost bit s1 excellent performer well great sound great comfort wonderful cable design comes solidly made case lots eartips highly recommend sample provided review \n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[\\s]+\"\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.replace(pat=pattern, repl=\" \", regex=True)\n",
    "\n",
    "print(df[\"preprocessed\"].iloc[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dd832",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "081d3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im', 'big', 'fan', 'brainwavz', 's1', 'actually', 'headphones', 'yet', 'disappointed', 'products', 's1', 'main', 'set', 'active', 'use', 'e', 'g', 'workouts', 'runs', 'etc', 'since', 'flat', 'cable', 'durable', 'resistant', 'tangles', 's5', 'keeps', 'good', 'features', 's1', 'adds', 'sound', 'quality', 'richer', 'better', 'defined', 'thats', 'say', 's1', 'sounds', 'poor', 'quite', 'good', 'fact', 's5', 'better', 'highs', 'better', 'defined', 'midrange', 'punch', 'bass', 'comes', 'clearly', 'without', 'moving', 'harsh', 'territory', 'volume', 'pushed', 's1s', 'overall', 'sound', 'quality', 'pleasing', 'build', 'quality', 'seems', 'solid', 'solid', 's1', 'better', 'love', 'flat', 'cable', 'know', 'thats', 'something', 'appreciated', 'everyone', 'working', 'wonderfully', 'although', 'brainwavz', 'headsets', 'comes', 'excellent', 'hard', 'shell', 'case', 'usually', 'tote', 'earbuds', 'wrapped', 'around', 'mp3', 'player', 'pocket', 'easy', 'carry', 'stressful', 'cables', 'lead', 'tangles', 'round', 'wires', 'flat', 'wires', 'especially', 'thick', 'jacket', 'survive', 'abuse', 'zero', 'problems', 'earbuds', 'sleekly', 'shaped', 'style', 's1', 'comfort', 'line', 'customary', 'brainwavz', 'style', 'say', 'outstanding', 'comes', 'wide', 'range', 'tips', 'fit', 'pretty', 'much', 'ear', 'plus', 'comply', 'foam', 'tips', 'favorite', 'fitted', 'properly', 'end', 'zero', 'ear', 'irritation', 'plus', 'excellent', 'sound', 'isolation', 'bass', 'response', 'ear', 'design', 'much', 'like', 's1', 'never', 'used', 'design', 'prior', 's1', 'take', 'little', 'time', 'get', 'accustomed', 'became', 'second', 'nature', 'quickly', 'design', 'lot', 'stable', 'exercising', 'conventional', 'ear', 'design', 'expensive', 's1', 'hear', 'difference', 'price', 'still', 'looking', 'keep', 'cost', 'bit', 's1', 'excellent', 'performer', 'well', 'great', 'sound', 'great', 'comfort', 'wonderful', 'cable', 'design', 'comes', 'solidly', 'made', 'case', 'lots', 'eartips', 'highly', 'recommend', 'sample', 'provided', 'review', '']\n"
     ]
    }
   ],
   "source": [
    "corpora = df[\"preprocessed\"].values\n",
    "tokenized = [corpus.split(\" \") for corpus in corpora]\n",
    "\n",
    "print(tokenized[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9707e",
   "metadata": {},
   "source": [
    "# Phrase Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4129d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "bi_gram = Phrases(tokenized, min_count=300, threshold=50)\n",
    "\n",
    "tri_gram = Phrases(bi_gram[tokenized], min_count=300, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161c6ef",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8780258",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_gram_tokens = set([token for text in tokenized for token in text])\n",
    "uni_gram_tokens = set(filter(lambda x: x != \"\", uni_gram_tokens))\n",
    "\n",
    "print(list(uni_gram_tokens)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8638d3",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_min = bi_gram.min_count\n",
    "\n",
    "bi_condition = lambda x: x[1] >= bigram_min\n",
    "\n",
    "bi_gram_tokens = dict(filter(bi_condition, bi_gram.vocab.items()))\n",
    "bi_gram_tokens = set([token.decode(\"utf-8\") \\\n",
    "                      for token in bi_gram_tokens])\n",
    "\n",
    "bi_grams_only = bi_gram_tokens.difference(uni_gram_tokens)\n",
    "print(list(bi_grams_only)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e5fb2",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2af421",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_min = tri_gram.min_count\n",
    "\n",
    "tri_condition = lambda x: x[1] >= trigram_min\n",
    "\n",
    "tri_gram_tokens = dict(filter(tri_condition, tri_gram.vocab.items()))\n",
    "tri_gram_tokens = set([token.decode(\"utf-8\") \\\n",
    "                       for token in tri_gram_tokens])\n",
    "\n",
    "tri_grams_only = tri_gram_tokens.difference(bi_gram_tokens)\n",
    "print(list(tri_grams_only)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [Phraser(tri_gram)[Phraser(bi_gram)[i]] for i in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3462310",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [list(filter(lambda x: len(x) > 1, document)) \\\n",
    "             for document in tokenized]\n",
    "\n",
    "print(tokenized[1689185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53b23a",
   "metadata": {},
   "source": [
    "# Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45925003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "vocabulary = Dictionary(tokenized)\n",
    "\n",
    "vocabulary_keys = list(vocabulary.token2id)[0:10]\n",
    "\n",
    "for key in vocabulary_keys:\n",
    "    print(f\"ID: {vocabulary.token2id[key]}, Token: {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c7445",
   "metadata": {},
   "source": [
    "# Count-based Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957349fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorization Converting text to numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197fd8a9",
   "metadata": {},
   "source": [
    "# Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [vocabulary.doc2bow(doc) for doc in tokenized]\n",
    "\n",
    "for idx, freq in bow[0]:\n",
    "    print(f\"Word: {vocabulary.get(idx)}, Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b6c61",
   "metadata": {},
   "source": [
    "# TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "tfidf = TfidfModel(bow)\n",
    "\n",
    "for idx, weight in tfidf[bow[0]]:\n",
    "    print(f\"Word: {vocabulary.get(idx)}, Weight: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086d9d1",
   "metadata": {},
   "source": [
    "# Word Embedding for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "feature_size = 100\n",
    "context_size = 20\n",
    "min_word = 1\n",
    "\n",
    "word_vec= word2vec.Word2Vec(tokenized, size=feature_size, \\\n",
    "                            window=context_size, min_count=min_word, \\\n",
    "                            iter=50, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abace4",
   "metadata": {},
   "source": [
    "# Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_unpack = [(word, idx.index) for word, idx in \\\n",
    "                   word_vec.wv.vocab.items()]\n",
    "\n",
    "tokens, indexes = zip(*word_vec_unpack)\n",
    "\n",
    "word_vec_df = pd.DataFrame(word_vec.wv.syn0[indexes, :], index=tokens)\n",
    "\n",
    "display(word_vec_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized_array = np.array(tokenized)\n",
    "\n",
    "model_array = np.array([word_vec_df.loc[doc].mean(axis=0) for doc in tokenized_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dae199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(model_array)\n",
    "model_df[\"label\"] = df[\"overall\"]\n",
    "\n",
    "display(model_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2f919",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#sampling the model_df population\n",
    "pca_df = model_df.reset_index()\n",
    "pca_df = model_df.dropna(axis=0).iloc[:,1:]\n",
    "pca_df = pca_df.iloc[::50]\n",
    "\n",
    "#setting up PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca = pca.fit_transform(pca_df.iloc[:, :-1])\n",
    "labels = pca_df[\"label\"]\n",
    "\n",
    "#setting up plot components\n",
    "x_axis = pca[:,0]\n",
    "y_axis = pca[:,1]\n",
    "color_map = pca_df[\"label\"].map({1:\"blue\", \\\n",
    "                                 2:\"red\", \\\n",
    "                                 3:\"yellow\", \\\n",
    "                                 4:\"green\", \\\n",
    "                                 5:\"orange\"})\n",
    "\n",
    "#plotting PCA\n",
    "f, axes = plt.subplots(figsize=(20,10))\n",
    "plt.scatter(x_axis, y_axis, color=color_map, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e0f47",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0eb5b",
   "metadata": {},
   "source": [
    "## More on Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db35932",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_bank = [\"nook\", \"phone\", \"tv\", \"good\", \"price\"]\n",
    "\n",
    "for word in word_bank[:]:\n",
    "    related_vec = word_vec.wv.most_similar(word, topn=5)\n",
    "    related_words = np.array(related_vec)[:,0]\n",
    "    word_bank.extend(related_words)\n",
    "    print(f\"{word}: {related_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54e22e",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=5, n_iter=1000, random_state=42)\n",
    "\n",
    "sample_vecs = word_vec.wv[set(word_bank)]\n",
    "sample_tsne = tsne.fit_transform(sample_vecs)\n",
    "tsne_x = sample_tsne[:, 0]\n",
    "tsne_y = sample_tsne[:, 1]\n",
    "\n",
    "f, axes = plt.subplots(figsize=(20,7))\n",
    "ax = plt.scatter(x=tsne_x, y=tsne_y)\n",
    "\n",
    "for label, x, y in zip(word_bank, tsne_x, tsne_y):\n",
    "    plt.annotate(label, xy=(x+3, y+3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c373bf26",
   "metadata": {},
   "source": [
    "## Word Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c5579",
   "metadata": {},
   "source": [
    "### Books + Touchscreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec.wv.most_similar(positive=[\"books\", \"touchscreen\"], \\\n",
    "                      negative=[], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7a7a7",
   "metadata": {},
   "source": [
    "### Cheap – Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec.wv.most_similar(positive=[\"cheap\"], \\\n",
    "                      negative=[\"quality\"], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea2d8f",
   "metadata": {},
   "source": [
    "### Tablet – Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6377d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec.wv.most_similar(positive=[\"tablet\"], \\\n",
    "                      negative=[\"phone\"], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209f66e",
   "metadata": {},
   "source": [
    "## Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful = df[\"helpful\"].tolist()\n",
    "most_helpful = max(helpful, key=lambda x: x[0])\n",
    "\n",
    "most_helpful_idx = df[\"helpful\"].astype(str) == str(most_helpful)\n",
    "most_helpful_idx = df[most_helpful_idx].index\n",
    "\n",
    "most_helpful_text = df[\"reviewText\"].iloc[most_helpful_idx].values[0]\n",
    "\n",
    "print(most_helpful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee981dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import spacy\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "ner = spacy.load(\"en\")\n",
    "\n",
    "ner_helpful = ner(most_helpful_text)\n",
    "\n",
    "ner_dict = defaultdict(list)\n",
    "for entity in ner_helpful.ents:\n",
    "    ner_dict[entity.label_].append(entity)\n",
    "\n",
    "for NER, name in ner_dict.items():\n",
    "    print(f\"{NER}:\\n{name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(ner_helpful, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1801e5",
   "metadata": {},
   "source": [
    "## Dependency Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_displacy(sentence):\n",
    "    ner_sentence = ner(sentence)\n",
    "    displacy.render(ner_sentence, jupyter=True, \\\n",
    "                    options={\"compact\": False, \\\n",
    "                             \"distance\": 90, \\\n",
    "                             \"word_spacing\":20, \\\n",
    "                             \"arrow_spacing\":10, \\\n",
    "                             \"arrow_stroke\": 2, \\\n",
    "                             \"arrow_width\": 5})\n",
    "\n",
    "for sentence in most_helpful_text.split(\".\")[0:3]:\n",
    "    ner_displacy(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4866",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "num_topics = 10\n",
    "bow_lda = LdaMulticore(bow, num_topics=num_topics, id2word=vocabulary, \\\n",
    "                       passes=5, workers=cores, random_state=42)\n",
    "\n",
    "for token, frequency in bow_lda.show_topic(0, topn=5):\n",
    "    print(token, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in range(0, num_topics):\n",
    "    print(f\"\\nTopic {topic+1}:\")\n",
    "    for token, frequency in bow_lda.show_topic(topic, topn=5):\n",
    "        print(f\" {token}, {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad627fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_idm = pyLDAvis.gensim.prepare(bow_lda, bow, vocabulary)\n",
    "\n",
    "pyLDAvis.display(lda_idm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68de0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92965ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
